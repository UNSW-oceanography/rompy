{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backend System Examples\n",
    "\n",
    "This notebook demonstrates the usage of rompy's backend system for running models, processing outputs, and orchestrating complete workflows.\n",
    "\n",
    "The backend system provides three types of components:\n",
    "- **Run Backends**: Execute models in different environments\n",
    "- **Postprocessors**: Process model outputs after execution\n",
    "- **Pipeline Backends**: Orchestrate complete workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "from rompy.model import ModelRun\n",
    "from rompy.core.config import BaseConfig\n",
    "from rompy.core.time import TimeRange\n",
    "\n",
    "# Configure logging to see backend activity\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Create a Basic Model Run\n",
    "\n",
    "First, let's create a basic model run that we can use to demonstrate the different backends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory for outputs\n",
    "output_dir = tempfile.mkdtemp(prefix=\"rompy_backend_demo_\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Create a model run\n",
    "model = ModelRun(\n",
    "    run_id=\"backend_demo\",\n",
    "    period=TimeRange(\n",
    "        start=datetime(2023, 1, 1, 0),\n",
    "        end=datetime(2023, 1, 1, 6),\n",
    "        interval=\"1H\"\n",
    "    ),\n",
    "    output_dir=output_dir,\n",
    "    config=BaseConfig(arg1=\"demo\", arg2=\"backend_test\"),\n",
    "    delete_existing=True\n",
    ")\n",
    "\n",
    "print(f\"Model run created: {model.run_id}\")\n",
    "print(f\"Period: {model.period.start} to {model.period.end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering Available Backends\n",
    "\n",
    "Let's see what backends are available in the current environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rompy.model import RUN_BACKENDS, POSTPROCESSORS, PIPELINE_BACKENDS\n",
    "\n",
    "print(\"Available Run Backends:\")\n",
    "for name, backend_class in RUN_BACKENDS.items():\n",
    "    print(f\"  - {name}: {backend_class.__name__}\")\n",
    "\n",
    "print(\"\\nAvailable Postprocessors:\")\n",
    "for name, processor_class in POSTPROCESSORS.items():\n",
    "    print(f\"  - {name}: {processor_class.__name__}\")\n",
    "\n",
    "print(\"\\nAvailable Pipeline Backends:\")\n",
    "for name, pipeline_class in PIPELINE_BACKENDS.items():\n",
    "    print(f\"  - {name}: {pipeline_class.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Backends\n",
    "\n",
    "Run backends execute the model in different environments. Let's demonstrate the available backends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Backend\n",
    "\n",
    "The local backend runs the model directly on the current system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with local backend (default)\n",
    "print(\"Running with local backend...\")\n",
    "success = model.run(backend=\"local\")\n",
    "\n",
    "print(f\"Run successful: {success}\")\n",
    "\n",
    "# Check what files were created\n",
    "output_path = Path(output_dir) / model.run_id\n",
    "if output_path.exists():\n",
    "    files = list(output_path.rglob(\"*\"))\n",
    "    print(f\"\\nFiles created: {len(files)}\")\n",
    "    for file in files[:5]:  # Show first 5 files\n",
    "        print(f\"  - {file.relative_to(output_path)}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"  ... and {len(files) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker Backend (if available)\n",
    "\n",
    "The Docker backend runs the model inside a Docker container. This requires Docker to be installed and running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Docker backend is available\n",
    "if \"docker\" in RUN_BACKENDS:\n",
    "    print(\"Docker backend is available!\")\n",
    "    \n",
    "    # Note: This example shows the syntax but may fail if Docker is not available\n",
    "    # or if the required image is not present\n",
    "    try:\n",
    "        print(\"\\nAttempting to run with Docker backend...\")\n",
    "        print(\"(This may fail if Docker is not available or configured)\")\n",
    "        \n",
    "        success = model.run(\n",
    "            backend=\"docker\",\n",
    "            image=\"ubuntu:20.04\",  # Simple base image for demonstration\n",
    "            executable=\"/bin/echo\",  # Simple command that will succeed\n",
    "            env_vars={\"TEST_VAR\": \"backend_demo\"}\n",
    "        )\n",
    "        \n",
    "        print(f\"Docker run successful: {success}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Docker run failed (expected if Docker not available): {e}\")\n",
    "else:\n",
    "    print(\"Docker backend is not available in this environment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocessors\n",
    "\n",
    "Postprocessors handle model outputs after execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No-op Postprocessor\n",
    "\n",
    "The no-op postprocessor is a placeholder that performs no operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the no-op postprocessor\n",
    "print(\"Running no-op postprocessor...\")\n",
    "results = model.postprocess(processor=\"noop\")\n",
    "\n",
    "print(f\"Postprocessing results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Postprocessor Example\n",
    "\n",
    "Let's create a simple custom postprocessor to demonstrate how to extend the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "class FileCountPostprocessor:\n",
    "    \"\"\"A simple postprocessor that counts files in the output directory.\"\"\"\n",
    "    \n",
    "    def process(self, model_run, **kwargs) -> Dict[str, Any]:\n",
    "        \"\"\"Count files in the model output directory.\"\"\"\n",
    "        output_path = Path(model_run.output_dir) / model_run.run_id\n",
    "        \n",
    "        if not output_path.exists():\n",
    "            return {\n",
    "                \"success\": False,\n",
    "                \"message\": \"Output directory does not exist\",\n",
    "                \"file_count\": 0\n",
    "            }\n",
    "        \n",
    "        # Count files\n",
    "        file_count = sum(1 for f in output_path.rglob(\"*\") if f.is_file())\n",
    "        total_size = sum(f.stat().st_size for f in output_path.rglob(\"*\") if f.is_file())\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"message\": f\"Found {file_count} files\",\n",
    "            \"file_count\": file_count,\n",
    "            \"total_size_bytes\": total_size,\n",
    "            \"output_directory\": str(output_path)\n",
    "        }\n",
    "\n",
    "# Use our custom postprocessor\n",
    "print(\"Running custom file count postprocessor...\")\n",
    "custom_processor = FileCountPostprocessor()\n",
    "results = custom_processor.process(model)\n",
    "\n",
    "print(f\"Custom postprocessing results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Backends\n",
    "\n",
    "Pipeline backends orchestrate the complete workflow from model generation through execution to postprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Pipeline\n",
    "\n",
    "The local pipeline backend executes the complete workflow locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh model run for the pipeline demo\n",
    "pipeline_model = ModelRun(\n",
    "    run_id=\"pipeline_demo\",\n",
    "    period=TimeRange(\n",
    "        start=datetime(2023, 1, 1, 0),\n",
    "        end=datetime(2023, 1, 1, 3),\n",
    "        interval=\"1H\"\n",
    "    ),\n",
    "    output_dir=output_dir,\n",
    "    config=BaseConfig(arg1=\"pipeline\", arg2=\"demo\"),\n",
    "    delete_existing=True\n",
    ")\n",
    "\n",
    "# Run the complete pipeline\n",
    "print(\"Running complete pipeline...\")\n",
    "results = pipeline_model.pipeline(\n",
    "    pipeline_backend=\"local\",\n",
    "    run_backend=\"local\",\n",
    "    processor=\"noop\"\n",
    ")\n",
    "\n",
    "print(f\"\\nPipeline results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "The backend system provides clear error messages when backends are not found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use a non-existent run backend\n",
    "try:\n",
    "    model.run(backend=\"nonexistent\")\n",
    "except ValueError as e:\n",
    "    print(f\"Run backend error: {e}\")\n",
    "\n",
    "# Try to use a non-existent postprocessor\n",
    "try:\n",
    "    model.postprocess(processor=\"invalid\")\n",
    "except ValueError as e:\n",
    "    print(f\"Postprocessor error: {e}\")\n",
    "\n",
    "# Try to use a non-existent pipeline backend\n",
    "try:\n",
    "    model.pipeline(pipeline_backend=\"unknown\")\n",
    "except ValueError as e:\n",
    "    print(f\"Pipeline backend error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Workflow Example\n",
    "\n",
    "Let's put it all together with a complete workflow that demonstrates the full capability of the backend system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comprehensive workflow\n",
    "workflow_model = ModelRun(\n",
    "    run_id=\"complete_workflow\",\n",
    "    period=TimeRange(\n",
    "        start=datetime(2023, 1, 1, 0),\n",
    "        end=datetime(2023, 1, 1, 12),\n",
    "        interval=\"3H\"\n",
    "    ),\n",
    "    output_dir=output_dir,\n",
    "    config=BaseConfig(\n",
    "        arg1=\"complete\",\n",
    "        arg2=\"workflow\",\n",
    "        description=\"Demonstration of complete backend workflow\"\n",
    "    ),\n",
    "    delete_existing=True\n",
    ")\n",
    "\n",
    "print(\"=== Complete Workflow Demo ===\")\n",
    "print(f\"Model: {workflow_model.run_id}\")\n",
    "print(f\"Period: {workflow_model.period}\")\n",
    "print(f\"Output: {workflow_model.output_dir}\")\n",
    "\n",
    "# Step 1: Generate input files\n",
    "print(\"\\n1. Generating input files...\")\n",
    "workflow_model.generate()\n",
    "print(\"   ✓ Input files generated\")\n",
    "\n",
    "# Step 2: Run the model\n",
    "print(\"\\n2. Running model...\")\n",
    "run_success = workflow_model.run(backend=\"local\")\n",
    "print(f\"   ✓ Model run: {'Success' if run_success else 'Failed'}\")\n",
    "\n",
    "# Step 3: Process outputs\n",
    "print(\"\\n3. Processing outputs...\")\n",
    "process_results = workflow_model.postprocess(processor=\"noop\")\n",
    "print(f\"   ✓ Postprocessing: {process_results['message']}\")\n",
    "\n",
    "# Step 4: Complete pipeline (alternative approach)\n",
    "print(\"\\n4. Alternative: Complete pipeline in one call...\")\n",
    "pipeline_results = workflow_model.pipeline(\n",
    "    pipeline_backend=\"local\",\n",
    "    run_backend=\"local\",\n",
    "    processor=\"noop\"\n",
    ")\n",
    "print(f\"   ✓ Pipeline: {'Success' if pipeline_results['success'] else 'Failed'}\")\n",
    "\n",
    "print(\"\\n=== Workflow Complete ===\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated the key features of rompy's backend system:\n",
    "\n",
    "1. **Run Backends**: Execute models in different environments (local, Docker)\n",
    "2. **Postprocessors**: Process model outputs with custom logic\n",
    "3. **Pipeline Backends**: Orchestrate complete workflows\n",
    "4. **Extensibility**: Easy to create and register custom backends\n",
    "5. **Error Handling**: Clear error messages for debugging\n",
    "\n",
    "The entry point-based architecture makes it easy to extend rompy with custom backends without modifying the core library. Simply implement the required interface and register your backend through Python entry points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup: Remove temporary files\n",
    "import shutil\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(f\"Cleaned up temporary directory: {output_dir}\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not clean up {output_dir}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}